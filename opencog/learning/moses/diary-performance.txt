
Diary of performance measurements and tuning for MOSES
------------------------------------------------------

Maintained by Linas Vepstas. The contents below are not going to be
explained in terribly great detail; this is for my personal use, and
not a tutorial for the general public.  If you are a moses hacker,
maybe this data will be interesting.  I'm only checking this into bzr
so that I don't accidentally loose this data.  

Timing measurements are very specific for my own computer; your results
will be different.  Results will change as algorithms are modified; the
below is being used to help me get baseline performance numbers, to
understand how modifications affect performance, and to help make sure
there are no regressions.

Diary started in January 2012

Opencog revision 6386:
----------------------
-Hpa -k3 -m50000    (3-parity)
-r0: 0m15.051s
-r1: 0m1.406s
-r2: 0m15.265s
-r3: 0m3.281s
-r4: 0m17.628s
-r5: 0m3.876s
-r6: 0m5.590s
-r7: 0m22.319s
-r8: 0m19.817s
-r9: 0m3.958s


-Hpa -k4 -m50000
(no r flag):  0m52.547s (best is -1)
-r1: 0m51.907s  (also -1, as are result unless otherwise indicated)
-r2: 1m26.161s
-r3: 1m1.008s  (best is -2)
-r4: 1m26.425s
-r5: 1m15.517s
-r6: 1m24.877s
-r7: 0m53.119s (best is -2)
-r8: 1m4.888s
-r9: 1m20.561s (best is -2)

To get the above in later versions, need to use -L1 -T1 flags.

circa revision 6541:
--------------------
time opencog/learning/moses/main/moses -Hpa -k3 -m50000
(no -r flag): 0m0.892s
-r0: 0m0.535s
-r1: 0m0.796s
-r2: 0m7.317s
-r3: 0m1.334s
-r4: 0m0.895s
-r5: 0m8.400s
-r6: 0m2.420s
-r7: 0m10.862s
-r8: 0m2.026s
-r9: 0m7.471s

avg: 4.19 (approx)

Again, Now with -L1 -T1:
-r0: 0m9.078s
-r1: 0m1.556s
-r2: 0m23.966s
-r3: 0m3.546s
-r4: 0m5.201s
-r5: 0m4.385s
-r6: 0m9.747s
-r7: 0m9.991s
-r8: 0m19.364s
-r9: 0m9.968s

avg: 9.68 (approx)

So the 'true hillclimbing' is 2.3x faster thanold stuff, for this.

Now try 4-parity...
-Hpa -k4 -m50000
-r0: 158 secs, -1 score
-r1: 2m23.313s  (a -1 solution)
-r2: 2m30.541s  (also -1, as are rest, unless indicated).
-r3: 1m40.566s  (bravo perfect score!)
-r4: 1m39.910s (best is -2)
-r5: 2m4.012s
-r6: 2m39.442s
-r7: 0m42.020s (perfect score)
-r8: 1m42.506s (-2)
-r9: 2m9.784s (-2)

so recap: -Hpa -k4 -m50000
perfect score: 2
-1 score: 5
-2 score: 3

So -m50K is not enough.

try again -m150K
-Hpa -k4 -m150000
-r0: 278.223783 secs perfect score
-r1: -1
-r2: 180.539163 secs perfect score
-r3: 97.197070 secs perfect score
-r4: -2
-r5: 142.639202
-r6: -1
-r7: 42.500166
-r8: -1
-r9: -2

Note: perfect runtimes almost unchanged, and fewer loosers.

so recap: -Hpa -k4 -m150000
perfect score: 5
-1 score: 3
-2 score: 2

try again -m450K
-r0: 279.876706
-r1: -1
-r2: 185.149519
-r3: 97.226776
-r4: -1
-r5: 145.637475
-r6: -1
-r7: 43.974498
-r8: 709.072294
-r9: -1

so recap: -Hpa -k4 -m450000
perfect score: 6
-1 score: 4
-2 score: 0

try again -m1.6M
-r0: 286.623444  secs
-r1: -1
-r2: 196.127073
-r3: 100.873139
-r4: 1690.134350
-r5: 148.591779
-r6: 9752.876748
-r7: 51.243247
-r8: 731.033613
-r9: 2367.365400

Comments on above:
I've started trying to understand how hill-climbing actually works. Recall,
we now have two styles of hill-climbing, and each behaves differently.  The
"new style" does this:

-- construct representation by adding knobs
-- twiddle one knob at a time, till one knob causing greatest improvement is found.
-- repeat above step until no more improvement.
-- go back to step 1.

I ran above on 4-parity, with ten different random seeds (-r0 through -r9)
The time to solution (perfect score) depends *very strongly* on the random
seed. In one case, a solution is found in less than a minute; a few more
cases find a solution in 2-3-4 minutes anothr in 12 minutes, another in 25
minutes, another in 45 minutes, another in 3 hours. In one case, no perfect
score found after more than 3.5 hours search.


I've graphed these (see attachment) in order of discovery.  I am trying to
understand why this is happening, and what to do about it.  No clear ideas,
yet. 

I'm also trying to measure 4-parity using the "old-style" algo. Before I
describe this, one salient remark:  the above timings are independent of the
"max iterations" flag. That is, for "moses -Hpa -k4 -r2 -mNNN"  (4-parity,
rand-seed=2, max-iter=NNN)  then, if NNN is large enough, a perfect score is
obtained after 196 seconds, always, independent of NNN.  And if NNN is too
small, no solution is found.  I mention this, because it is very different
than the "old-style" behaviour.

=======================================

The "old-style" algorithm is this: (-L1 -T1)
-- step 1. construct representation by adding knobs
-- twiddle one knob at a time, till one knob causing greatest improvement is found.
-- if there's improvement, go to step 1.
-- if no improvement, twiddle two knobs simultaneously, and either go to step 1 or try 3
knobs. 
-- try up to five knobs, then go to step 1.

Now, all over again but with -L1 -T1
-Hpa -k4 -L1 -T1 -m50000
-r0: -1
-r1: -3
-r2: 70.442446
-r3: -1
-r4: -2
-r5: -4
-r6: -1
-r7: -2
-r8: -2
-r9: -3

-Hpa -k4 -L1 -T1 -m150000
-r0: 80.953417
-r1: -1
-r2: -1
-r3: -2
-r4: -2
-r5: -2
-r6: -2
-r7: -1
-r8: -2
-r9: 138.244841

-Hpa -k4 -L1 -T1 -m450000
-r0: 419.329227
-r1: 476.257538
-r2: -1
-r3: -1
-r4: -1
-r5: -2
-r6: 585.746513
-r7: 963.175023
-r8: -2
-r9: 413.799492

-Hpa -k4 -L1 -T1 -m1600000
-r0: 413.346996
-r1: 490.218301
-r2: 2844.111736
-r3: 1144.400860
-r4: 1110.296915
-r5: 1973.547115
-r6: 1012.321808
-r7: fail OOM 5.5 gigs virt, 3.7g RSS

Here, the behaviour is very different.  If NNN is small, then only one of
ten random seeds result in a solution, in about a minute. The other 9 are
wayy off.  If NNN is larger, two solutions are found, in about 2 minutes
each, the other 8 are way off, but not as bad as before.  There is no
solution in 1 minute!. The -r seed value that had previously found a soln
now finds no soln.

This pattern continues: for larger NNN, five solutions found, out of ten.
The fastest one found takes 8 minutes; the slowest took 15 minutes.  That
is, raising the max-iteration bound destroys the ability to find solutions
quickly for some random seeds, while improving  number of seeds that do lead
to solutions.  Very strange.

=======================================

Hypothesis: to answer question "why do some random seeds take so long w/
hill-climbing"?  Highest ranked exemplars, no matter how they are festooned
with knobs, have no knob settngs that improve the score. However, they have
many, many settings that provide an equivalent score, and none of these
dominate: thus the metapopulation keeps growing w/o bound. Thus, more and
more exemplars get explored, going down the list, until one gets deep into
the not-very-fit section of the metapopulation. Then, at last, an exemplar
is found that, when properly decorated, does have knob settings that result
in a solution.

Propose: instead of exploring metapopulation from highest score to lowest,
instead explore from lowest complexity to highest.  Problem: the correct
parity solution is going to have a high complexity...

Maybe weighted sum of complexity, score ...

plot:
deme generation, metapop size, score, complexity, evaluations.

cat moses.log | grep Stats | cut -d" " -f5

OK, so graphing the above states clearly indicates that the metapop grows
without bound.  up until point when an improved score is found, and then the
metapop is cut down to almost nothing at all.  Meanwhile, both score and
complexity are held constant for very long periods of time.  (err. best
score, and complexity of highest-ranked exemplar).

  -M [ --max-candidates ] arg (=-1)     Maximum number of considered candidates
                                        to be added to the metapopulation after
                                        optimizing deme.
                                        

graph: time to next discovery.
graph: eval time to num evals...
experiment: limit max metapop size.

Here's the old, uncapped, unlimited data:
with revised timings, due to code restructuring (stubbing out logger calls)
-r0: 410 gens 79883 evals   286 secs (262 secs revised)
-r1: -1
-r2: 196.127073 (revised 172 secs)
-r3: 100.873139 (revised 93 secs)
-r4: 1325 gens 486915 evals   1690 secs (revised 1560)  0.78 gens/sec  288 evals/sec
-r5: 148.591779 (revised 134)
-r6: 9752.876748
-r7: 130 gens 20432 evals  51 secs (revised 39 secs)  2.5 gens/sec   400 evals/sec
-r8: 510 gens 234820 evals 731.033613 (revised at 665 secs)
-r9: 2367.365400 (revised 2150 secs)


experiment: keep non-dominated exemplars only if they have a large hamming
distance between one-another.

Sucess! (kind of).... when limiting pool size to 1000 the -Hpa -k4 -r0 was solved in 98 secs
instead of 260 secs.  However, smaller limits did not work...
 Does sorting time make a big diff ?

-r0-capped: 217 gens, 38338 evals 98 secs
-r4-capped: 872 gens, 262530 evals 782 secs
-r7 capped: 507 gens, 97009 evals 310 secs   XXXX so this gets worse!!
-r8 capped: 788 gens, 265462 evals 698 secs   XXX this got worse ...

do r8, then r9 then r6

without the cap, get a population of over 6K towards the end.
-- propose: remove anything that's been tried already.
   tried that quickly, didn't seem to go well.  I don't like this idea...

idea:
-- limit the pool size to function of complexity:
   e.g. 20 bit complexity requires 2^20 = 10^6 for exhaustive enumeration.
   limit pool to 2^(complex/2) or 2^(2*complex/3) ... 

------
idea: select_exemplar() has a probability of selection that is SA-like.
try hotter temperatures. Origianlly have T=1

p = (p > 0 ? 0 : pow2((p - highest_comp)/T));

-1 means timoeut at 450K

        T=1     T=2    T=3
-r0:     262       8      4
-r1:  >19261      14    514   
-r2:     172    5371    444
-r3:      93    1168   5520
-r4:    1560    1131     58
-r5:     134     220   2106
-r6:    9752.x   502     53
-r7:      39      43   2566 
-r8:     665     324   6867
-r9:    2150     628    143        
-r10:     30     522    158
-r11:     15      67     77
-r12:    360    1656    700
-r13:    292     568    140
-r14:    961      20    931
-r15:   1972      83    306
-r16:     34     916   1547
-r17:   7138     187     90
-r18: >31836    2991     22  (-m1.1M)
-r19:    172     549    808

450K == 1/2 hour

re-sorting first ten by runtime:

# first column: original data
# second column: a 10% performance speedbump due to logging.
# third column: broaden the complexity chooser (by 2)
#
1  51.243247   39 8
2  100.873139  93 14
3  148.591779  134   43
4  196.127073  172   220
5  286.623444  262   324
6  731.033613  665   502
7  1690.134350 1560  628
8  2367.365400 2150  1134
9  9752.876748 9752  1168

restorting the first 20 by rutime:

#
# moses performance data, runtime in seconds
# using default hillclimbing.
# -Hpa -k4 in order of runtime
#
# first column: original data
# second column: a 10% performance speedbump due to logging.
# third column: broaden the complexity chooser (by 2)
# fourth column: broaden the complexity chooser (by 3)
#
# in select_exemplar():
# p = (p > 0 ? 0 : pow2((p - highest_comp)/T));
#
#   orig       T=1    T=2    T=3
1   15          15      8      4
2   30          30     14     22
3   34          34     20     53
4   51.24       39     43     58
5   100.87      93     67     77
6   148.59     134     83     90
7   172        172    187    140
8   196.12     172    220    143
9   286.62     262    324    158
10  292        292    502    306
11  360        360    522    444
12  731.03     665    549    514
13  961        961    568    700
14  1690.13   1560    628    808
15  1972      1972    916    931
16  2367.36   2150   1131   1547
17  7138      7138   1168   2106
18  9752.87   9752   1656   2566
# 19 >19261 at -m1 for T=1
19  9999     19261   2991   5520
# 20  >31836 at -m1.1M for T=1
20  9999      31836  5371   6867


Email 6 Feb 2012:
As mentioned before, the run-time performance of MOSES in finding a
perfect solution to certain problems can sometimes take an exponentially
long time, dependeing on the initial random seed.  I sent a graph
before, and attached is a new one. As before, I've been focusing on the 
4-parity problem.

For those runs that tak huge amounts of time to solve, what appears to
be happening is that the algo quickly finds a fairly good solution,
matching all but one of the posible outputs, and then gets hung up. It
examines huge numbers of exemplars, attaching knobs to each, twiddling
these, finding plenty of new, non-dominated solutions. But it just can't
find a fitter solution.  So, it occurred to me, perhaps it is failing to
look at a diverse-enough set of initial exemplars.  I assumed that the
algo was selecting the fittest possible exemplar, with the lowest
possible complexity, and trying to mutate that. I figured that,
perhaps, it would work faster if it occasionally attempted mutating
some high-complexity exemplar.  (This was directly inspired by the other
chain of emails).

This is done in select_exemplar(). Turns out, the code was already doing
the above. That is, even the so-called "hill-climbing" code doesn't
hill-climb when picking an exemplar; instead it implements a 
simulated-annealing-style algo. It didn't always pick the
lowest-complexity exemplar to mutate, it sometimes did pick something
more complex.  The problem is that the temperature was set too low.
It didn't try the high-complexity exemplars often enough.  So I
twiddled, and got the graph below.

The label "pow2(-complexity/T)" refers to the line of code in
select_exemplar().  I tried T=1,2,3. (T is the tmerpature; this is the
Bolzmann distribution).  The original code had a hard-coded T=1 in it.

-- Runtime improves by a factor of 2x or better for T=2, usually.
   (The green line) Sort-of. Almost 10x better for the high-runtime
   cases, but worse on the medium runtime cases.
-- The exponential behavriour does not go away.  The overall slope
   is unchanged.  The slope is bad: The fastest case takes 4 seconds.
   Half the time, a perfect solution is found in under 300 seconds.
   Half the time, a perfect solution requires much much much more than
   that: sometimes many many hours.

I'd like to try other temperatures, and a larger dataset, but this
all requires a lot of cpu time.  Working on it ... 

I've checked in code for this, but its not in final form yet.

---------------------------------------------------

As above, but for T=2 in select_exemplar() temperature, comparing
capped and uncapped metapop size.

       uncapped   capped
-r0:        8        8
-r1:       14       14
-r2:     5371    >5957
-r3:     1168      358
-r4:     1131      680
-r5:      220     1082
-r6:      502      371
-r7:       43       41
-r8:      324       59
-r9:      628       67
-r10:     522       35
-r11:      67      161
-r12:    1656      548
-r13:     568    >5553
-r14:      20      104
-r15:      83     1299
-r16:     916       94
-r17:     187      459
-r18:    2991     1211
-r19:     549       43

Wow! a clear winner!
Temp=2 clamped, avg time== 913 secs

And again for temp=1

                clamped
        T=1       T=1
-r0:     262      494
-r1:  >19261      226
-r2:     172      834
-r3:      93      108
-r4:    1560       72
-r5:     134      398
-r6:    9752.x   4559
-r7:      39      135
-r8:     665      212
-r9:    2150      927
-r10:     30      770
-r11:     15     2225
-r12:    360      646
-r13:    292     3522
-r14:    961      871
-r15:   1972       68
-r16:     34       70
-r17:   7138    >5948
-r18: >31836      235
-r19:    172     2028

Temp=1 clamped, avg time== 1221 secs
Wow .. a clear looser!

         T=3    clamped
-r0:        4      4
-r1:      514   1047
-r2:      444    118
-r3:     5520    855
-r4:       58     60
-r5:     2106    192
-r6:       53     46
-r7:     2566   2074
-r8:     6867    235
-r9:      143    138 
-r10:     158    936
-r11:      77    114
-r12:     700   1268
-r13:     140     35
-r14:     931    128
-r15:     306   1260
-r16:    1547     34
-r17:      90    722
-r18:      22     39
-r19:     808    860


avg clamped == 508 -- wow this is the best yet ... 
There's no long-running outliers to pull the thing way out ... 
graph shows that T=2 is still the best, so use that in the code.

Current consolidated dataset:

#
# moses performance data, runtime in seconds
# using default hillclimbing.
# -Hpa -k4 in order of runtime
#
# first column: original data
# second column: a 10% performance speedbump due to logging.
# third column: broaden the complexity chooser (by 2)
# fourth column: broaden the complexity chooser (by 3)
# fifth col: T=2 and clamped metapop size.
#
# in select_exemplar():
# p = (p > 0 ? 0 : pow2((p - highest_comp)/T));
#
#                                 clamp  clamp  clamp 
#   orig       T=1    T=2    T=3   T=2    T=1    T=3
1   15          15      8      4     8     68      4
2   30          30     14     22    14     70     34
3   34          34     20     53    35     72     35
4   51.24       39     43     58    41    108     39
5   100.87      93     67     77    43    135     46
6   148.59     134     83     90    59    212     60
7   172        172    187    140    67    226    114
8   196.12     172    220    143    94    235    118
9   286.62     262    324    158   104    398    128
10  292        292    502    306   161    494    138
11  360        360    522    444   359    646    192
12  731.03     665    549    514   371    770    235
13  961        961    568    700   358    834    722
14  1690.13   1560    628    808   459    871    835
15  1972      1972    916    931   548    927    855
16  2367.36   2150   1131   1547   680   2028    860
17  7138      7138   1168   2106  1082   2225   1047
18  9752.87   9752   1656   2566  1211   3522   1260
# 19 >19261 at -m1.1M for T=1,  >6666 at -m1.6M
19  9999     19261   2991   5520  6666   4559   1268
# 20  >31836 at -m1.1M for T=1  the 6666 7777 values are bogus
20  9999      31836  5371   6867  7777   6666   2074


See http://blog.opencog.org/2012/02/07/tuning-moses/ for written
explanation.
==================================================================

Try again with -I1 .. what will this do??
Also explore -P pos_size_ratio

As above, for T=2 in select_exemplar() temperature, comparing
capped and uncapped metapop size.  (capped is done via the auto-capping
mechanism that is the current default.)

Third column is with -I1 spec'ed, so that metapop includes dominated
exemplars.

forth column: -P40 -- pop-size-ratio = 40

       uncapped   capped   domin   P40    P10
-r0:        8        8       8      9      8
-r1:       14       14      15     15     15
-r2:     5371    >5957   >1453  >1574  >1623
-r3:     1168      358     344    356    358
-r4:     1131      680     662    698    718
-r5:      220     1082    1022   1090   1136
-r6:      502      371     374    374    407
-r7:       43       41      44     43     44
-r8:      324       59      62     61     63
-r9:      628       67      69     68     69
-r10:     522       35      36     35     36
-r11:      67      161     160    159    163
-r12:    1656      548     543           567
-r13:     568    >5553   >1355         >1496
-r14:      20      104     108           109
-r15:      83     1299    1290          1351
-r16:     916       94      92            93
-r17:     187      459     502           477
-r18:    2991     1211   >1147         >1185
-r19:     549       43      45            45


Looks like a tie to me... 
Upshot: using the -I1 flag to keep dominated exemplars in the population
does not seem to affect runtime. I'm guessing that this is because the
dominated exemplars are never selected.

==================================================================

Modified sort order:
bool composite_score::operator>(const composite_score &r)
{
   return (3*first + second) > (3*r.first + r.second);
}

This results in the metapop being kept in a different order, for
example, the first 12 entries might be this:

metap 0 score=-5 complex=-8
metap 1 score=-5 complex=-8
metap 2 score=-8 complex=0
metap 3 score=-6 complex=-6
metap 4 score=-6 complex=-6
metap 5 score=-6 complex=-6
metap 6 score=-6 complex=-6
metap 7 score=-5 complex=-9
metap 8 score=-5 complex=-9
metap 9 score=-5 complex=-9
metap 10 score=-8 complex=-1
metap 11 score=-8 complex=-1

OK, so 3 (plus auto-clamping) fails, no solutions found at all.
Disable autoclamping.  Gahh .. seems to run forever ... 
Redesign clamping ... 

Below, for different mixing weights W

         capped  W=4    W=5    W=6    W=8    W=3    W=2
-r0:        8     40      2     11     71    144   >516
-r1:       14    121     79    122     50  >1004   >536
-r2:    >5957     77     84    202  >1448    103   >543
-r3:      358    471     16     99    521     69   >556
-r4:      680     76     35     74  >1247    150   >503 
-r5:     1082    280     44     46     88    404   >524
-r6:      371     95    785    100     83    382   >541
-r7:       41    125    425     53    153     53   >510
-r8:       59     86  >1236  >1148    898     38   >525
-r9:       67     48     31  >1365  >1401     95   >551
-r10:      35     34     94     40     50    192   >528
-r11:     161    319    761   1060   1230    197   >552
-r12:     548     42    786    176  >1348     44   >545
-r13:   >5553    154     49    251  >1323     47   >508
-r14:     104     69    451    211     29     21   >545
-r15:    1299    287   1483    105    169    140   >551
-r16:      94  >1907     82     51    103    266   >509
-r17:     459    141    196    165    900    127   >508
-r18:    1211     87  >1095  >1123    402     93   >558
-r19:      43     73     72    630    392    188   >557


W=4 avg == 227

==================================================================

Arghhhh Move to floats, revamp, all changes

set weight to very large to regain old behaviour (i.e. rank first by
score, next by complexity).

As above -Hpa -k4 ...
-z12 -v1 -m50000  (90 seconds, when no solution)

negative numbers indicate no solution, and how many wrong the best
guess had.

z:    -z12  -z12   -z12   -z12   -z12   -z12    -z4    -z4   -z4    -z4
temp: -v100 -v50   -v20   -v10    -v5    -v2    -v5    -v2   -v1    -v3
-r0:   -2     -1     -1     -1     -1     -1     34     43    -1     30
-r1:   -1     80     -1     -2     16     30     72     -2    -1     -2
-r2:   -1     -1     65     36     33    111     34    155   150     -1
-r3:   14     -2     -2     -1     -2     -1     81     -1    -1     -3
-r4:   67     67     -1     -1     27     -2     69     -1    36     83
-r5:   -2     -2     -3     -3     -1     92     -1     -1    -2     -2
-r6:  102     -1     -1     10     29     -1     67     -2    -1     62
-r7:   -1     -1     -1     -2     -1     -2     21     77    45     -1
-r8:   -3    133     34     -1     -2     -2     39     52    62     84
-r9:   -2     -2     -1     -2     -1     -1     -1     18    22     16
-r10:  -2     -1     51     23     -2     -1     -1     -2    63     -2
-r11:  -1     -1     35    103     25     48     -2     -1    58    116
-r12:  -1     -1     29     -1     28     38     91     36    60     -1
-r13: 109     74     -1    105     -1     11     -1     -1   122     -1
-r14:  -2    103     -2     -1     45     53     21    172    -2    133
-r15:  -1     -1     -1    123     -1     86     -2     -2    -1     -1
-r16:  -1     -1     66     17     -2     -1     -1     16    -1     69
-r17:  -2     83     11     -1     89     -1    208     -2    -2     -1
-r18:  -1     -1     26     -1     -2     -1     75    147    -1     91
-r19:  41     91     -1     -2     -2     -1    113     -1    -1     -1

tot:    5      7      8      7      8      8     13      9     9

The tot bove is how many had perfect score, out of the 20.

Again, but this time with longer tun-times, for the graphs:
-m45000

z:        -z4     -z4
temp:     -v5     -v2
-r0:       34      43
-r1:       72     705
-r2:       34     770
-r3:       81     213
-r4:       69     426
-r5:      276     136
-r6:       67      -1
-r7:       21
-r8:       39
-r9:      279
-r10:     661
-r11:     243
-r12:      91
-r13:     152
-r14:      21
-r15:     282
-r16:     284
-r17:     208
-r18:      75
-r19:     113 

avg:      161

==================================================================
Above may bre non-reprodubile, due to changes in the max-pop-size logic.
So restart data collection.

As above -Hpa -k4 ...

z:      -z3   -z3   -z3   -z4   -z4   -z4   -z2   -z2 -z3.5 -z3.5 -z3.5
temp:   -v3   -v5   -v7   -v5   -v3   -v7   -v3   -v5   -v5   -v4   -v6
-r0:    308    19    24   711    42   631    -4    -4    24    59    33
-r1:    156   239    49   760   100   106    -4    -3    61   117   104
-r2:     72   230    76   103   802   136    -4         227    30    95
-r3:     84   349    83    73   296    48               207    41   101
-r4:    254    35   203   232    41    82                47   375    54
-r5:     85    94   168    19   109   337                22   110    23
-r6:    396    98   114    62   504   113               129    42   124
-r7:    182   715    17   586    43    88               222    66    28
-r8:     34    59   140   137    72   161               234   617    75
-r9:    819    73    71    25    14   132               125    24    61
-r10:   173   170   120   260   579  1166                34    19    27
-r11:    52    96    40    90   118   650               135    92    38
-r12:   188    16   716    70   701   670                21   241    23
-r13:   379    76   141   378   416   220               140    83    31
-r14:   136   518   502   230   242   560                88    52    51
-r15:   361    44    82    71   975    22                85   135   172
-r16:   250   258    74   261  1123   111                55    54     6
-r17:    34   387  1047   187   762   710               132   142    87
-r18:    11   168   516   183   183    85               114    33    15
-r19:    13     9    49   806    20   411                 5    10    52

avg:    199   183  211    262   357   322               105   117    60
120avg:       179                                       115
240avg:                                                             109

setting:  avg:   avg-over-what:
z3.5-v9   132    120 iter
z3.5-v7   110    120 iter
z3.5-v6   109    240 iter
z3.5-v5   115    120
z3.5-v4   131    120

Holy cow, that last one is smokin!
But a run over 240 different random seeds averaged out to only 109
seconds, not 60 seconds, so the smaller run just was not realistic.

==================================================================

-k5 results

                                   -m450K -m1.5M
     -z4v6 -z5v6 -z6v6 -z7v6 -z6v4  -z6v6 -z6v6
-r0    -8    -6    -6    -8    -6    -4     -3
-r1    -6    -8    -9    -6    -6    -4     -2
-r2    -8    -9    -5    -8    -5    -5     -3
-r3    -9    -6    -7    -8    -6    -3     -1
-r4    -6    -6    -9    -9    -9    -6     -1
-r5   -11    -8    -6    -7    -5    -6     -4
-r6    -6    -6    -6    -8    -6    -2   6881
-r7    -6    -9    -6   -10   -10    -2   3078
-r8    -4    -5    -7    -6    -8    -5
-r9    -8    -7    -7    -6    -6    -4
-r10   -7    -8    -6    -7    -7    -6
-r11   -6    -6    -6    -6   -10    -4
-r12   -9    -6    -5    -5    -7  1117 
-r13   -9    -7    -4    -7    -6    -4
-r14   -7    -7    -6    -6    -7    -4
-r15   -7    -8    -7    -7    -7    -5
-r16  -10    -5    -6    -5    -9    -5
-r17  -10    -5    -8   -10    -7    -4
-r18   -5   -10   -10    -6    -5    -4
-r19   -8    -6    -8    -5    -8    -3

best: -4x1       -4x1   
      -5x1 -5x3  -5x2   -5x3  -5x3
      -6x5 -6x7  -6x8   -6x6  -6x6

===========================================================
Is over-fitting a danger?  Well, we are over-fitting if the compexlity
of the solution formula approaches the complexity of the raw table of
data.  So lets compare them:

3-arity: 3 boolean-valued inputs one boolean-valued output,
total: 2^3=8 rows 4 bits per row: thus, complexity of table
is 4x8=32 bits.
typical moses solution: 10 or 11 bits.

4-arity: 4 boolean-valued inputs one boolean-valued output,
total: 2^4=16 rows 5 bits per row: thus, complexity of table
is 5x16=80 bits.
typical moses solution: 20 bits

Clearly, for the parity problem, the solution does not over-fit.

===========================================================
Data collected on the bank.dat test case.

Original hill-climbing algorithm:
moses -Hit -uQ3 -i bank.dat -W1

        score   time
-m10K:  -361     128
-m20K:  -278     487
-m40K:  -215    1808
-m80K:

Re-do -- the above had a bug in reduct, where the argmument of impulse()
was not being reduced.  Fixed in bzr commit 6586

          z-default             -z6 -vdefault      -z10, -v1
         score   time  plex  score  time  plex  score time   plex
-m10K:   -361     176   39   -346   194    34    -367  162    25
-m20K:   -258     477   47   -275   540    41    -274  656    51
-m40K:   -210    2496   71
-m80K:   -174   15445 
-m160K:  -159   50430

complexity of bank.dat:
91 lines, 38 bits input per line, one contin out, valued: 1-16: 4 bits
total: 91x42 = 3822 bits
Conclude: it'll be hard to over-fit the data, at the rate we are going.

Note really poor run-time performance of above.  This seems to be due to
this:  First, we build a fairly small exemplar, and hill-climb it... but
not until exhaustion, because the hill-climbing budget is badly
calculated.  Then, for the second round, we build a massively complex
exemplar, which is very expensive to evaluate... and then we don't even
beother to exhaust the nearest-neighbor search before throwing it away.
Solution: at least do an exhaustive search for closes
nearest-neightbors, before giving up.  This seems to help:

          z-default           exhaust                copy avoid
         score   time  plex   score   time  plex   score   time   plex
-m10K:   -340    45     14    -340     45    14    -340     41    14
-m20K:   -265   167     30    -265    171    32    -265    162    32
-m40K:   -228   658     52    -248   3103    40
-m80K:                        -219  11117    50
-m160K:                       -196  29415    60
-m320K:                        4 gigs ram...

Gahh ... -m40K goes to 3103 seconds, -248 score, -40 complexity when
the first search is exhausted, and the second exemplar gets built.
The second exemplar is huge/complex, and very slow to evaluate...

OK, "Select candidates to merge" is taking too long:
11904 in 1:35:23 or 5723 secs = 480 millisecs each
8754 in 2:16 or 136 secs = 15 millisecs each
29846 in 4:19:24 = 15563 secs = 520 millisecs each

The "copy avoid" columns avoid a few pointless copies of the combo
tree to the stack.

Performance of 
        auto select_candidates =
in metapopulation.h is still a disaster area.


======================================================================
Regression test the rebudgeting.  

The "budge" column shows the effect of exhaustive nearest-neighbor
search in hill-climbing.  Conclusion: this is a sure-fire win! Woot!

As above -Hpa -k4 -z3.5 -v5

         orig  budge
-r0:      24    23
-r1:      61    60
-r2:     227   144 
-r3:     207    36
-r4:      47    45
-r5:      22    22
-r6:     129   115
-r7:     222    58
-r8:     234   351
-r9:     125    54
-r10:     34    33
-r11:    135    44
-r12:     21    20
-r13:    140    70
-r14:     88   116
-r15:     85    70
-r16:     55   107
-r17:    132   195
-r18:    114   104
-r19:      5     5

avg:     105    84

