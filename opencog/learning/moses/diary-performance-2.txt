
    Diary of MOSES performance and Enhancement Work
    -----------------------------------------------
       Linas Vepstas -- started June 2014


Diary of notes, thoughts, measurements, pertaining to work on MOSES.

Boosting in MOSES
-----------------
There are several very different ways of envisioning boosting in MOSES,
each being more or less compatible with the formal definition of
boosting. See http://en.wikipedia.org/wiki/Boosting_(meta-algorithm)

(Caution: the formulas in http://en.wikipedia.org/wiki/AdaBoost
are incorrect and misleading, and suggests an inapprorpriate algorithm
and implementation. Beware!)

The formal definition of boosting invokes the idea of a weighted
ensemble of 'weak learners'.  Each member of the ensemble is given a
weight, with the weights being issued so as to minimize the total error
of the prediction being made by the ensemble. The accuracy of the
ensemble is then measured, and used to identify those samples in the
training set that are being classified incorrectly.  New weak learners
are then trained, with an emphasis on correctly classifying those
samples that were gotten incorrect by the ensemble.

For MOSES, it appropriate definition of 'ensemble' is ambiguous.
The ensemble can be: 

  A) The set of instances in the current deme
  B) The evolutionary history of a given exemplar
  C) The collection of combo trees (exemplars) in the metapopulation.
  D) Some combination of the above.

Let's recall the definition of an exemplar, a deme, and a
metapopulation.

 *) An 'exemplar' is a single, fixed combo tree.  It has some
    evolutionary heritage, having evolved from earlier trees.

 *) The metapopulation is the current collection of the fittest
    (most accurate) exemplars.

 *) A deme is an exemplar that has been decorated with knobs, together
    with a large set of possible knob settings (instances).  Each
    instance is conceptually a single combo tree, that differs
    structurally from its parent exemplar in some 'minor' way.

Lets look at how the boosting algo would work for each scenario. But
first, lets sketch the current 'hill-climbing' algo, as currently
performed by MOSES.

--------------
Hill-climbing) The current canonical algo.

 H.1) Select an exemplar from the metapopulation, create deme.
 H.2) Generate N instances by turning N knobs.
 H.3) Score all N instances, using a uniform weight on all samples.
 H.4) Select the highest-scoring instance. (this is the hill-climb).
 H.5) Go to step H.2

 H.6) Terminate above loop in some way. (e.g. top of hill reached)
 H.7) Put M of the top-scoring instances into the metapopulation.
 H.8) Go to step H.1

 H.9) Terminate above loop in some way.
 H.10) Use the top K exemplars in the metapopulation to create a
       traditional ensemble, for off-line prediction/classification.


--------------
Scenario A) The set of instances is an ensemble.  In this scenario, the
boosting algorithm becomes a variant the current 'hill-climbing' algo.
The steps are numbered below so that they correspond to the
hill-climbing steps. To summarize: step H.3 is replaced by the Boost
algo, so that H.3 is a bunch of steps.

 A.1) Select an exemplar from the metapopulation. (same as H.1)
 A.2) Generate N instances by turning N knobs. (same as H.2)
 A.3.1) Score all N instances, using a uniform weight on all samples.
 A.3.2) Pick the best instance, per boost, add it to the ensemble.
 A.3.3) Adjust per-sample weight based on ensemble mis-prediction
 A.3.4) Re-score remaining N-1 instances with new weighted scorer.
 A.3.5) Go to step A.3.2

 A.3.7) Terminate above loop using some criteria,
 A.4) Select the highest-scoring instance, based on the weighted
      scorer available at termination time.
 A.5) Go to step A.2 (Same as H.5)

 A.6.1) Terminate above loop in some way. (e.g. top of hill reached)
 A.6.2) Discard all row-weights.
 A.7) Put M of the top-scoring instances into metapop.  (Same as H.7)
 A.8) Go to step A.1 (Same as H.8)

 A.9) Same as H.9
 A.10) Same as H.10

The above seems to make sense, and superfically seems to be compatible
with the formal definition of boosting.  However, step A.4 seems somewhat
strange. Lets ponder this.

In step A.4, we pick the instance with the highest weighted score,
rather than the instance with the highest overall accuracy. What does
this mean?  What effect does this have?  Well, it selects for an
instance that gets right what previous instances got wrong.  By the time
that we get past step A.7, what we've done is to create M exemplars that
got things right that the initial exemplar did not.  Do any of these M
exemplars have a better absolute value accuracy score than the initial
exemplar? Unclear, possibly not.  So we have research question 1:

 RQ.1) Compare the 'raw' score of the M exemplars from step A.7 to the
       score from ordinary hill-climbing H.7.  Is it possible that the
       weighted hill-climb of step A.4 somehow avoided a plateau that
       H.4 may have gotten stuck in?  viz. Can scenario A) boosting
       actually outperform ordinary hill-climbing? (At each step?)

 RQ.2) Is the final metapopulation of A.10 stronger/fitter/better than
       that of H.10, given same amount of CPU time?  (Hill-climbing is
       less CPU intensive, so can perform more iterations).

--------------
Secnario B) The ensemble is the evolutionary history of an exemplar.

There's actually two Scenario B's. So:

----
Scenario Ba) Just like Scenario A, except that at step A.6.2, we save
the final weights, associate them with this particular exemplar.  These
weights are then used in step A.3.1, instead of a uniform distribution.

This begs the question:
  RQ.3) Is scenario Ba better than plain-A?  It seems to offer some kind
        of continuinty with what came before, but does that matter?  The
        only reason the top-of-hill A.6.1 is evaded is because the knobs
        are all different ...

----
Scenario Bh) Just like plain-old hill-climbing H, except that steps H.3
and H.7 are modified. Step H.7 is replaced by the boost algo, with step
H.3 using the appropriate boosting scoring function.

 Bh.1) Select an exemplar from the metapopulation. (Same as H.1)
 Bh.2) Generate N instances by turning N knobs. (Same as H.2)
 Bh.3x) Score all N instances, using a weight distribution that was
        previously saved with the exemplar.
 Bh.4) Select the highest-scoring instance. (Same as H.4)
 Bh.5) Go to step Bh.2 (Same as H.5)

 Bh.6) Terminate above loop in some way. (e.g. top of hill reached)
 Bh.7.1) Select M top-scoring instances. 
 Bh.7.2) Add that instance to an ensemble that contains its parent.
 Bh.7.3) Update row weights for this ensemble.
 Bh.7.4) Place the ensemble into the metapopulation.
 Bh.8) Go to step Bh.1 (Same as step H.8)

Here, the ensemble consists only of an exemplar, and all of its parents
from which it is descended.  These seems to be rather thin.  The problem
is that step 6-8 don't happen that often -- and so the ensembles never
get very big.  Naively, boosting would seem to work best when the
ensembles have many members. This begs the question:

 RQ.4) How big to the ensembles get, for the Bh approach?

and 
 RQ.5) Same as RQ.2 -- net-net, is this better?

--------------
Secnario C) Maintain an ensemble drawn from the metapopulation.

Again, this is a variant of the canonical hill-climbing algo, with
modifications show below.  To summarize, step H.7 is replaced by the
boost algo.  Unlike Bh.7, though, the ensemble is drawn from the
entire metapop.

 C.1) Select an exemplar from the metapopulation. (Same as H.1)
 C.2) Generate N instances by turning N knobs. (Same as H.2)
 C.3x) Score all N instances, using weighted scorer.
 C.4) Select the highest-scoring instance. (Same as H.4)
 C.5) Go to step C.2 (Same as H.5)

 C.6) Terminate above loop in some way. (Same as H.6)
 C.7.1) From 1 till M, do:
 C.7.2) Pick the best instance, per boost, add it to the ensemble.
 C.7.3) Adjust per-sample weight based on instance mis-prediction.
 C.7.5) Re-score remaining M-1 instances with new weighted scorer.
 C.7.6) Place all instances into the metapop.
 C.7.7) Go to step C.7.2

 C.8) Go to step C.1 (Same as H.8)

 C.9) Terminate above loop in some way. (Same as H.9)
 C.10) Use the ensemble built in step C.7.2 as the final output of
       the process. i.e. The ensemble is what is finally used for
       off-line prediction/classification.

Scenario C appears to be the one that is closest in spirit to the 
traditional boosting algos, and thus will be implemented first.

Scenario C does have interesting issues with the metapopulation
management.  With each iteration, the scoring criteria for managing the
metapopulation will change, and the metapop will contain a mixture of
trees from earlier rounds, and the current round.  This poses a
question: 

 RQ.6) Should the metapop be rescored with the new re-weighted scorer,
       or is it OK to leave stale score in there?

Design issues
-------------
How to implement Scenario C:
- Add single weight to scored combo tree. 

- Maintain a weight column .. where? In a new boosing scorer.
  Needs to be like the behave_cscore, but different.

Scoring Requirements:
1) hill-climber needs a *single* scalar score, to determine which way is "up".
2) This scalar score needs to be a sum of:
   a) a complexity penalty, obtained from the combo tree,
   b) a diversity penalty, based on
      i) the metapopulation
      ii) possibly the behavioral score
      iii) possibly the combo tree
   c) a function of the behavioral score, such as a direct sum,
      or possibly a weighted bscore (e.g. via boosting).

3) Multiple tables will be explicitly NOT supported. Why? Because its
   not clear how to combine these.  One way would be to combine them
   into one big table.  Another possibility is to use a different
   bscorer on each; but I don't know of a use-case for that.  I don't
   know how to weight these relative to one-another.  So, for now, 
   bonly one table.

Solution:
-- remove multibscore (done)
-- provide a utility for #2 that assembles a composite score from the 
   parts, and can be queried for the scalar score. Done: its behave_cscore.

Notes/TODO:
-- complexity is not being factored in ...  Done.
-- scorer is currently not using the user-specified weight column !?
   Done.  I thinnk there's nothing to do ... except maybe test ... 
-- create unit test for boosting
-- document eval-table
   maybe rename eval-combo, or eval-combo-table

Problems:
1) best score must now be the ensemble score.
2) the "update best cands" is no longer trying to beat the best in the
   metapop, because the criteria for "best" haas changed.  This seems to
   mean that the entire metapop needs to be rescored.  Maybe leave this
   as open question.




What is a deme_t?

typedef instance_set<composite_score> deme_t;
struct instance_set : public vector<scored_instance<ScoreT> >
All instances in instance set have same field description.

why is there ever more than one instance set??

==============

24 June 2014
------------
Compare the boosted & non-boosted version of the parity problem.

Time to perfect score:
time moses -Hpa -k3 --boost=1  : 1/2 second
time moses -Hpa -k4 --boost=1  : 1.8 seconds
time moses -Hpa -k5 --boost=1  : 9.2 seconds
time moses -Hpa -k6 --boost=1  : 6m13 seconds

Wow!  Recall that without boosting, -k4 would take minutes, (depending
very strongly on the initial random seed) and that -k5 was mostly 
unsolvable (would take an hour or two for a few lucky random seeds)

Wow, even -k6 finds a solution, although it is long, and takes much
more time to find.   ... and needs to have --reveist=50

So: -k4 speedup == 100x roughly
    -k5 speedup == more than 500x

Hmm  different rand seeds:

           -k4     -k5      -k6      -k6
 random    time    time     time     size
  seed    (secs)  (secs)   (secs)  (trees)
 ------   ------  ------   ------  -------
   r0      1.8      11.2     568
   r1      1.8       9.2     392
   r2      2.5      10.4     190
   r3      2.6      11.8     260
   r4      2.3       9.2     260     633
   r5      2.2      18.0    2385    2244
   r6      1.8      12.7     152     413
   r7      2.6      13.5    2360    2266
   r8      2.0      12.3     501     963
   r9      2.0       9.9    1207    1644

size(trees) above it the number of trees in the ensemble.

crazy ideas:

one rather crazy experiment would be to find three with almost equal
scores, combine them as indicated, run reduct, and then repeat.  How
badly would this damage things?  Would it be an effective way of
obtaining a single tree that is almost right, and then can be finished
off in the usual fashion?

or perhaps the weights should be forced to be valued as small fractions,
so that they can be exactly combined ... 

July 2014
---------
Discrete AdaBoost reference:

 * Yoav Freund, Robert E. Schapire, "A Short Introduction to Boosting"
   (1999) Journal of Japanese Society for Artificial Intelligence, vol. 14
   issue 5 pp 771-780

Boosting as gradient-descent, for contin-valued problems:
 * Robert E. Schapire, YoramSinger, "Improved boosting algorithms using
   confidence-rated predictions." (1998) Proc 11th Ann Conf Computational
   Learning Theory pp 80-91

Outlier mitigation:
 * GentleAdaBoost
 * BrownBoost


Selection scoring with boosting
-------------------------------

Performance of the selectionUTest on select.csv with differrent evals:

     num_evals  error   dedupe   nodupe
     ---------  -----   ------   ------
          1K     58      29        32
          2K     58      29        32 
          5K     56      29        28
         10K     56      28        22
         20K     56      20        11
         40K     56      15         1
         80K     56      15         1

This is a very degenerate dataset: select.csv contains a total of 329 rows.
Of these only 60 are unique, so max score can't really do better than that.

Evaluation halts after after 49K evals ... 

The dedupe column shows results for the select-less-dupe.csv file  This one
has 329 rows, of which  286 are unique.

The nodupe column shows results for the select-no-dupe.csv file  This one
has 329 rows, all of which are unique.

Above results are off-by-one, final results are 55, 14 and 0 not 56, 15 and 1.

Arghh. Also, inappropriatte weight tallys.  Redo the above.
select.csv has 329 rows. The 0.8 and 0.9 bounds are at
   select_bscore: lower_bound = 1329.39 upper bound = 1650.22

XXXXX TODO


Localized Boosting; Mixture of Experts
--------------------------------------
To be used with the pre scorer. 

The pre scorer is used to mine for "experts": combo trees that give
correct answers only on that subset of positive results that they are
certain about.

To boost the pre scorer, the boosting discriminator needs to:
-- get rewarded for TP answers
-- get punished for FP answers
-- no-op for FN, TN answers

Thus, the weights only get adjusted for rows that are part of the
positive set. 


search terms:
-- localized boosting  LocBoost
-- boosting by resampling.


Localized Boosting
------------------
Definition: "Localized Boosting" and the LocBoost algo is used to
train and apply experts only in a "local" part of the dataset. That
is, the experts are expert only for those inputs that are near (e.g
Hamming-distance-near) to thier domain of expertize.  This idea makes
sense if the inut data is real-valued but low-dimensional: the local
experts are expert only in some submanifold of R^n.  For us, the input
is high-dimensional and is boolean.


Irrelevant variables, Ignored variables, Local experts.
-------------------------------------------------------
The precision-scorer does this: a given combo tree pays attention to
only certain inputs, but ignores all others.  If those inputs are
present/absent, then the row is selected.  However, it could happen
that the training set simply did not include (enough) values of the
ignored variables that could be important.  Thus, an expert should be
considered to be "reliable" if, for the subset that it selects, the
ignored variables are uniformly distributed.   We do not currently
make this kind of a check for truly irrelevant variables

The idea of localized boosting is to say "this expert is an expert
only when the pattern is selected *and also* the input training set
had a uniform distribution on these specific ignored variables".
If the training set did not have a uniform distribution of *some*
of the ignored variables, then the expert is no longer expert for
those cases (e.g. the confidence is ranked lower).


Precision, selection base results
---------------------------------
Create 3 files with top scorers marked s boolean 1 else 0.
select.csv: 70% mark should be at 0.7*329 = 230.2 so should
have 230 lines marked with 0 and 99 lines marked with 1.

   954.393 < div < 955.542

So preselect.csv is select.csv, with all scores above 955 are marked.
Ditto, preselect-less-dupe.csv and preselect-no-dupe.csv.

The result are tables w/ 329 data points, of which 230 lines are
false, 99 are true. (i.e. 230/329 = 70% of lines...)

Compare the -Hit and -Hselect scorer directly on preselect-no-dupe.csv

The 4 columns below are:

moses -Hit -Yval -ipreselect-no-dupe.csv 
moses -Hit -Yval -ipreselect-no-dupe.csv --boost=1
moses -Hselect  -iselect-no-dupe.csv -q0.7
moses -Hselect  -iselect-no-dupe.csv -q0.7 --boost=1


     num_evals  Hit         Hit            Hselect     Hselect
                  (time)   boost (time)      (time)  boost (time)
     --------- ---------   ------------   ----------  ----------
        10K    46 (0m17s)    30 (0m15s)   48 (0m19s)  36 (0m14s)
        20K    41 (0m42s)    22 (0m47s)   36 (0m39s)  21 (0m41s)
        40K    29 (2m34s)     8 (2m8s)    27 (2m24s)   6 (1m46s)
        80K    24 (9m21s)     0 (4m35s)   26 (8m40s)   0 (2m56s)
       160K    22 (30m18s)    -           22 (24m10s)  -

Conclude: The differences between Hit and Hselect are small and would
surely wash out if the results were averaged over different initial
random seeds. This is not a surprise; both scorers are doing essentially
the same thing for this dataset.  So the above is really just a
"sanity check" to make sure that the code is good, and, indeed, it
seems to be good.

--------------------------------------------

Try again on the dataset with duplicates. As before, there are 329 rows
total, with 230 false, and 99 true.  However, due to duplicates, the
best possible score is -50, and the effective length is 329-2*50=229.

moses -Hit -Yval -ipreselect.csv 
moses -Hit -Yval -ipreselect.csv --boost=1
moses -Hselect  -iselect.csv -q0.7
moses -Hselect  -iselect.csv -q0.7 --boost=1


     num_evals  Hit         Hit            Hselect     Hselect
                  (time)   boost (time)      (time)  boost (time)
     --------- ---------   ------------   ----------  ----------
         5K                   3 (0m6s)                 4 (0m7s)
        10K    29 (0m16s)     0 (0m11s)   29 (0m16s)   0 (0m12s)
        20K     4 (0m35s)     -            4 (0m36s)   -
        40K     4 (1m24s)     -            4 (1m24s)   -
        80K     4 (4m7s)      -            4 (4m2s)    -
       160K     0 (4m45s)     -            0 (11m38s)  -


Notes:
-- preselect.csv has best score of 50, due to duplicate rows.
   All reported scores are realtive to this score.

-- The Hselect and the Hit scorers behave nearly identically, as
   expected for this case.


===============
The bug below got fixed. The fix is to always score relative to the
best-possible score.

Since there are 329 rows, this means 329-51 = 278 rows, half of which
are 278/2 = 139 which is what the ensemble scorer needs to beat.

wtf:  -51 + 87 = 36 / 329

OK, so this looks like a bug to me; number of rows is being handled
incorrectly for the degenerate boosted case.
behave_len is wrong for ensemble err.

We need: 
 non-degenerate, non weighted:
      best score = 0 so  err = score / num rows; 

 non-degenerate, weighted:
      best score = 0 so  err = score / weighted num rows; 
      since the score is weighted.

      e.g. two rows with weights: 
           0.1
           2.3
      so if 0.1 wrong, then err = 0.1/2.4
      and if 2.3 is wrong, err = 2.3/2.4  

 degenerate, non-weighted:

      best score > 0   err = (score - best_score) / eff_num_rows;

      where eff_num_rows = sum_row fabs(up-count - down-count)
      (its also the "worst possible score")

      e.g. five uncompressed rows:
           up:1  input-a  
           dn:2  input-a
           up:2  input-b
      best score is 1 (i.e. is 4-5 where 4 = 2+2).
      so if first is wrong, then err = (1-1)/5 = 0/3
      so if second is wrong, then err = (2-1)/5 = 1/3
      so if third & first is wrong, then err = (3-1)/3 = 2/3
      so if third & second is wrong, then err = (4-1)/3 = 3/3
      
However, above is wrong because -very-best needs to be rescaled too..

===========================

Precision scoring
-----------------
Results for the Hpre scorer, using the same datasets as above.

Results depend sharply on the complexity ratio and the temperature,
a quick sniff test shows: -z150 for the ratio and -v25 for the
temperature seem to work very well for preselect-no-dupe.csv and

-z150 -v25 for preselect-no-dupe.csv
-z350 -v45 for preselect.csv

   moses -Hpre -q0.05 -Yval -ipreselect.csv

Max attainable precision on preselect.csv should be: 
(329-50)/329 = 0.848024
  

     num_evals  preselect       no-dupe       
                      (time)       (time)  
     --------- --------------   ---------
        10K    0.78476 (0m14s)  1.0 (0m2s)
        40K    0.78947 (3m31s)

Above: the no-dupe column uses -v25 -z150
the plain  preselect column uses -v45 -z350

Results might improve with additional tuning; but this requires
averaging over multiple random seeds.

-------------------------
General strategy:

current scorer:
  if row picked, sum the outputs (= 0.5 *pos - neg)
  active += pos+neg (weighted correctly)

  row score = sum of outputs / total weight of selected.

best-possible-score:
   tree picks only rows that are true positives, never picks
   rows that are true negatives.

   Ergo, this should be 1/total active weight


ensemble addition:
   If a selection has perfect score, then add it to the ensebmle
   with ??? weight.

   +1 for every correct entry
   less for partially correct...

   If its perfect, and activation is high enough, then we are done
   (the single solution is sufficient)

   If its perfect, but activation too low, then add with ??? weight.

   If its not perfect, means some selections are wrong.
   two alternatives:
    a) just don't add it.
    b) add it, but ... ?

ensemble scoring: 
   Members in ensemble select rows.  Alternatives:
    a) if ensemble selects, then done, because selection is never
       wrong, because we never added wrong selectors.
       (ensemble members are T to select or F for don't-care) 

    b) ensemble is sometimes wrong, selecting bad rows.  How
       can this be corrected?  How do I un-select? 
       b1) alter weights so that bad rows are almost never
           selected again by new ensemble members.
       b2) add a dual un-select ensemble, which un-selects
           bad rows.

yet another alternative;
    c) if a row is correctly selected, decrease its weight.
       if a row is incorrectly selected, don't admit to ensemble.
       if a row is not selected, but should have been, increase
       its desirablilty.

row weights: these need to be normalized to sum to 1.0

row weight adjust:
  w[i] *= rcpalpha if selected & right
       *= expalpha if selected & wrong
       *= 1.0 if not selected.

Strategy A:
-----------
-- Accept a tree into ensemble only if it has perfect score. 
   The weight it is given does not matter.
-- Decrease the weight of the rows it selects.  Increase the
   weights of all the other rows.  The idea is to have it focus on
   those rows it hasn't learned.  These weights will affect the
   optimization (hill-climbing) stage.
-- The returned get_weighted_tree() also needs modification.

Strategy B:
-----------
-- Maintain two ensembles: one that selects, and one that
   anti-selects.  However, these require two distinct metapops,
   one metapop to train each.
-- This allows imperfect selectors to be admitted into the ensemble,
   as long as a counter-manding selector is found for the badly-choosen
   rows.
-- The above seems too complex, for now.

Strategy C:
-----------
-- Allow imperfect selectors into the ensemble.  Problem: this makes
   it unclear on how the ensemble chooses: does a row need a minimum
   number of votes to be elected? What is that minimum? Is it ad-hoc?
   Is there a running-bias that we can maintain to find this minimum?

   i.e. bad rows are being selected with strrength s; thus, the ensemble
   should reject all rows with a vote of less than s. 


Boosted pre-scorer results
--------------------------
Strategy A has been implemented. Since the ensemble always has a
precision of 1.0, the actual score is always 1.0 - activation_penalty.

Columns are:
no-dupe: -i preselect-no-dupe.csv -Hpre -Yval -q0.05 -z150 -v25 --boost=1
presel: -i preselect.csv -Hpre -Yval -q0.05 -z350 -v45 --boost=1

     num_evals  no-dupe         presel
                      (time)       (time)  
     --------- --------------   --------------
        10K    0.50226 (0m21s)  0.27912 (0m16s)
        20K    0.50226 (1m25s)  0.80556 (0m59s)
        40K    0.68458 (4m36s)  0.80488 (3m48s)
        80K    1.0     (6m8s)   0.80000 (14m15s) 

The last one went down!  How odd ... 

But an activation of 0.05 seems far too easy.  Try again with -q0.25:

     num_evals  no-dupe          presel
                      (time)        (time)  
     --------- --------------    --------------
        10K    -1.10718 (0m21s)  -1.33032 (0m16s)
        20K    -1.10718 (1m27s)  -0.02069 (0m57s)
        40K    -0.92486 (4m50s)   0.10869 (3m39s)
        80K    -0.46532 (17m4s)   0.30226 (14m48s)

Both these activations are still pathetic ... 

Comparable non-boosted results:

     num_evals  no-dupe          presel
                      (time)        (time)  
     --------- --------------    --------------
        10K    0.5 (0m15s)       0.5 (0m25s)
        20K    0.5 (0m52s)       0.5 (1m28s)
        40K


     num_evals  preselect       no-dupe       
                      (time)       (time)  
     --------- --------------   ---------
        10K    0.78476 (0m14s)  1.0 (0m2s)
        40K    0.78947 (3m31s)


The precision scorer just strikes me as being awfully underwhelming ... 



Future directions
-----------------
* Explore the "local expert" idea above.
* Try to understand the underlying claim about getting good results
  from the precision scorer.

