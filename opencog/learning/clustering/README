
                      Clustering
                      ----------
                       May 2014

This directory is going to contain some relatively simple, quick-n-dirty
clustering algorithms for extracting the number of clusters, and their
sizes, given only a collection of objects, and the pair-wise distances
between them.  Currently, the primary consumer of this code is planned
to be MOSES; the clustering is neede to get a sensation of the diversity
of the demes being trained in MOSES.  That is, given a collection of
combo trees, and some distance measure between them, the goal is to see
how many of these are similar, and how many are different, and what the
variation within a cluster might be.

Note: the above mis-uses the word "distance". The actual pair-wise
numbers might not actually be distances in the strict sense; that is,
they might not obey the triangle inequality.

k-means
gussian clustering

References:
-----------
http://en.wikipedia.org/wiki/Spectral_clustering
http://en.wikipedia.org/wiki/K-means_clustering
http://en.wikipedia.org/wiki/Expectation-maximization_algorithm
http://en.wikipedia.org/wiki/DBSCAN
http://en.wikipedia.org/wiki/OPTICS_algorithm

Comments:
---------
The DBSCAN, OPTICS and BIRCH algorithms assume spatial data: i.e. true
distance measures (metrics, e.g. Euclidean space).  We do not have that.
They also seem to work well only for low-dimensional data.

We don't have that much data, so BIRCH is overkill.

EM (expectation maximization) might work; I sort-of a-priori expect the
clusters to be Gaussian, but I don't really know that yet...
